{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7203454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44cdf394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "llm=init_chat_model(\"openai:gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e376ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load And Embed Documents\\n\",\n",
    "docs = TextLoader(\"sample_docs.txt\", encoding=\"utf-8\").load()\n",
    "chunks = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50).split_documents(docs)\n",
    "vectorstore = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c1029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Agent State\n",
    "class IterativeRAGState(BaseModel):\n",
    "    question: str\n",
    "    refined_question: str = \"\"\n",
    "    retrieved_docs: List[Document] = []\n",
    "    answer: str = \"\"\n",
    "    verified: bool = False\n",
    "    attempts: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33fc2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieve Node\n",
    "def retrieve_docs(state: IterativeRAGState) -> IterativeRAGState:\n",
    "        query = state.refined_question or state.question\n",
    "        docs = retriever.invoke(query)\n",
    "        return state.model_copy(update={\"retrieved_docs\": docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d82e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reflect And Verify\\n\",\n",
    "def generate_answer(state: IterativeRAGState) -> IterativeRAGState:\n",
    "    context = \"\".join(doc.page_content for doc in state.retrieved_docs)\n",
    "    prompt = f\"\"\"Use the following context to answer the question:\n",
    "    Context:\n",
    "    {context}\n",
    "    Question:\n",
    "    {state.question}\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt.strip()).content.strip()\n",
    "    return state.model_copy(update={\"answer\": response, \"attempts\": state.attempts + 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c7bcb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reflect on answer\\n\",\n",
    "def reflect_on_answer(state: IterativeRAGState) -> IterativeRAGState:\n",
    "    prompt = f\"\"\"\n",
    "    Evaluate whether the answer below is factually sufficient and complete.\n",
    "    Question: {state.question}\n",
    "    Answer: {state.answer}\n",
    "    Respond 'YES' if it's complete, otherwise 'NO' with feedback.\n",
    "    \"\"\"\n",
    "    feedback = llm.invoke(prompt).content.lower()\n",
    "    verified = \"yes\" in feedback\n",
    "    return state.model_copy(update={\"verified\": verified})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67fe7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Refine query\\n\",\n",
    "def refine_query(state: IterativeRAGState) -> IterativeRAGState:\n",
    "    prompt = f\"\"\"\n",
    "    The answer appears incomplete. Suggest a better version of the query that would help retrieve more relevant context.\n",
    "    Original Question: {state.question}\n",
    "    Current Answer: {state.answer}\n",
    "    \"\"\"\n",
    "    new_query = llm.invoke(prompt).content.strip()\n",
    "    return state.model_copy(update={\"refined_question\": new_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37d985c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(IterativeRAGState)\n",
    "builder.add_node(\"retrieve\", retrieve_docs)\n",
    "builder.add_node(\"answer\", generate_answer)\n",
    "builder.add_node(\"reflect\", reflect_on_answer)\n",
    "builder.add_node(\"refine\", refine_query)\n",
    "builder.set_entry_point(\"retrieve\")\n",
    "builder.add_edge(\"retrieve\", \"answer\")\n",
    "builder.add_edge(\"answer\", \"reflect\")\n",
    "builder.add_conditional_edges(\n",
    "    \"reflect\",\n",
    "       lambda s: END if s.verified or s.attempts >= 2 else \"refine\"\n",
    ")\n",
    "builder.add_edge(\"refine\", \"retrieve\")\n",
    "builder.add_edge(\"answer\", END)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0a6059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final Answer: Agent loops and transformer-based systems are both integral components in the functioning of AI systems, but they serve different purposes and operate in distinct ways. Here‚Äôs how they relate to each other:\n",
      "\n",
      "1. **Agent Loops**:\n",
      "   - An agent loop consists of phases where an AI agent thinks (processes information and formulates a plan), acts (executes actions based on its plan), and observes (evaluates the results of its actions).\n",
      "   - This loop is critical for real-time adaptation and learning in dynamic environments. The feedback mechanism in the loop allows the agent to refine its actions over time, improving its effectiveness in achieving desired outcomes.\n",
      "   - Memory and planning are important for retaining historical context and anticipating future scenarios, while interactions with tools can enhance the agent's capabilities by providing additional resources or functionalities.\n",
      "\n",
      "2. **Transformer-Based Systems**:\n",
      "   - Transformers are a type of model architecture commonly used in natural language processing (NLP) tasks. They are designed to handle sequences of data and are known for their attention mechanism, which allows them to weigh the importance of different words or tokens in a sequence.\n",
      "   - Transformers operate mainly in the processing and generation of data, often focusing on understanding, summarizing, or predicting sequences based on large datasets.\n",
      "   - These models don't inherently operate with a feedback loop like agent loops, but they can be part of a larger system where the output from transformers informs the actions of an agent.\n",
      "\n",
      "In integrating agent loops with transformer-based systems, one might use the transformer model as a component within the \"thinking\" phase of the agent loop, where it can process inputs and generate responses based on complex data. The cycle of observing and acting around this process allows the system to incorporate the strengths of transformers (like complex decision-making and language understanding) into a dynamic, adaptable framework required for autonomous agents.\n",
      "üß† Verified: True\n",
      "üîÅ Attempts: 1\n"
     ]
    }
   ],
   "source": [
    "query = \"agent loops  and transformer-based systems?\"\n",
    "initial_state = IterativeRAGState(question=query)\n",
    "final = graph.invoke(initial_state)\n",
    "print(\"‚úÖ Final Answer:\", final[\"answer\"])\n",
    "print(\"üß† Verified:\", final[\"verified\"])\n",
    "print(\"üîÅ Attempts:\", final[\"attempts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a924876a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'agent loops  and transformer-based systems?',\n",
       " 'refined_question': '',\n",
       " 'retrieved_docs': [Document(id='1b80cff5-178c-4470-b5a8-ec96a5f7405f', metadata={'source': 'sample_docs.txt'}, page_content='An agent loop is the cycle of thinking, acting, and observing. It allows an AI agent to continuously refine its actions based on results.\\nThis feedback loop is crucial in autonomous systems to adapt in real-time.\\nAgent-based architectures benefit from memory, planning, and interaction with tools.')],\n",
       " 'answer': 'Agent loops and transformer-based systems are both integral components in the functioning of AI systems, but they serve different purposes and operate in distinct ways. Here‚Äôs how they relate to each other:\\n\\n1. **Agent Loops**:\\n   - An agent loop consists of phases where an AI agent thinks (processes information and formulates a plan), acts (executes actions based on its plan), and observes (evaluates the results of its actions).\\n   - This loop is critical for real-time adaptation and learning in dynamic environments. The feedback mechanism in the loop allows the agent to refine its actions over time, improving its effectiveness in achieving desired outcomes.\\n   - Memory and planning are important for retaining historical context and anticipating future scenarios, while interactions with tools can enhance the agent\\'s capabilities by providing additional resources or functionalities.\\n\\n2. **Transformer-Based Systems**:\\n   - Transformers are a type of model architecture commonly used in natural language processing (NLP) tasks. They are designed to handle sequences of data and are known for their attention mechanism, which allows them to weigh the importance of different words or tokens in a sequence.\\n   - Transformers operate mainly in the processing and generation of data, often focusing on understanding, summarizing, or predicting sequences based on large datasets.\\n   - These models don\\'t inherently operate with a feedback loop like agent loops, but they can be part of a larger system where the output from transformers informs the actions of an agent.\\n\\nIn integrating agent loops with transformer-based systems, one might use the transformer model as a component within the \"thinking\" phase of the agent loop, where it can process inputs and generate responses based on complex data. The cycle of observing and acting around this process allows the system to incorporate the strengths of transformers (like complex decision-making and language understanding) into a dynamic, adaptable framework required for autonomous agents.',\n",
       " 'verified': True,\n",
       " 'attempts': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
