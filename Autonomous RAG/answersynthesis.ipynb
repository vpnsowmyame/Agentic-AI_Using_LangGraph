{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80437089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders.youtube import YoutubeLoader\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "050353fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "llm=init_chat_model(\"openai:gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40441878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_retriever(file_path):\n",
    "        docs = TextLoader(file_path, encoding=\"utf-8\").load()\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        chunks = splitter.split_documents(docs)\n",
    "        vs = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
    "        return vs.as_retriever()\n",
    "def load_youtube_retriever():\n",
    "        # Mocked YouTube transcript text\n",
    "        content = \"\"\"\n",
    "        This video explains how agentic AI systems rely on feedback loops, memory, and tool use.\\n\",\n",
    "        It compares them to traditional pipeline-based LLMs. Temporal reasoning and autonomous tasking are emphasized.\\n\",\n",
    "        \"\"\"\n",
    "        doc = Document(page_content=content, metadata={\"source\": \"youtube\"})\n",
    "        vectorstore = FAISS.from_documents([doc], OpenAIEmbeddings())\n",
    "        return vectorstore.as_retriever()\n",
    "def wikipedia_search(query: str) -> str:\n",
    "    print(\"🌐 Searching Wikipedia...\")\n",
    "    return WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())(query)\n",
    "def arxiv_search(query: str) -> str:\n",
    "    print(\"📄 Searching ArXiv...\")\n",
    "    results = ArxivLoader(query).load()\n",
    "    return \"\".join(doc.page_content for doc in results[:2]) or \"No relevant papers found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80204845",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_retriever = load_text_retriever(\"sample_docs.txt\")\n",
    "youtube_retriever = load_youtube_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72eb9658",
   "metadata": {},
   "outputs": [],
   "source": [
    "### state\\n\",\n",
    "class MultiSourceRAGState(BaseModel):\n",
    "    question: str\n",
    "    text_docs: List[Document] = []\n",
    "    yt_docs: List[Document] = []\n",
    "    wiki_context: str = \"\"\n",
    "    arxiv_context: str = \"\"\n",
    "    final_answer: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a6425da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieval Nodes\\n\",\n",
    "def retrieve_text(state: MultiSourceRAGState) -> MultiSourceRAGState:\n",
    "    docs = text_retriever.invoke(state.question)\n",
    "    return state.model_copy(update={\"text_docs\": docs})\n",
    "def retrieve_yt(state: MultiSourceRAGState) -> MultiSourceRAGState:\n",
    "    docs = youtube_retriever.invoke(state.question)\n",
    "    return state.model_copy(update={\"yt_docs\": docs})\n",
    "def retrieve_wikipedia(state: MultiSourceRAGState) -> MultiSourceRAGState:\n",
    "    result = wikipedia_search(state.question)\n",
    "    return state.model_copy(update={\"wiki_context\": result})\n",
    "def retrieve_arxiv(state: MultiSourceRAGState) -> MultiSourceRAGState:\n",
    "    result = arxiv_search(state.question)\n",
    "    return state.model_copy(update={\"arxiv_context\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177a7133",
   "metadata": {},
   "outputs": [],
   "source": [
    "## synthesize\\n\",\n",
    "def synthesize_answer(state: MultiSourceRAGState) -> MultiSourceRAGState:\n",
    "    context = \"\"\n",
    "    context += \"[Internal Docs]\" + \"\".join([doc.page_content for doc in state.text_docs])\n",
    "    context += \"[YouTube Transcript]\" + \"\".join([doc.page_content for doc in state.yt_docs])\n",
    "    context += \"[Wikipedia]\" + state.wiki_context\n",
    "    context += \"[ArXiv]\" + state.arxiv_context\n",
    "    prompt = f\"\"\"You have retrieved relevant context from multiple sources. Now synthesize a complete and coherent answer.\\n\",\n",
    "    Question: {state.question}\n",
    "    Context:\n",
    "    {context}\n",
    "    Final Answer:\"\"\"\n",
    "    answer = llm.invoke(prompt).content.strip()\n",
    "    return state.model_copy(update={\"final_answer\": answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "164ab800",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(MultiSourceRAGState)\n",
    "builder.add_node(\"retrieve_text\", retrieve_text)\n",
    "builder.add_node(\"retrieve_yt\", retrieve_yt)\n",
    "builder.add_node(\"retrieve_wiki\", retrieve_wikipedia)\n",
    "builder.add_node(\"retrieve_arxiv\", retrieve_arxiv)\n",
    "builder.add_node(\"synthesize\", synthesize_answer)\n",
    "builder.set_entry_point(\"retrieve_text\")\n",
    "builder.add_edge(\"retrieve_text\", \"retrieve_yt\")\n",
    "builder.add_edge(\"retrieve_yt\", \"retrieve_wiki\")\n",
    "builder.add_edge(\"retrieve_wiki\", \"retrieve_arxiv\")\n",
    "builder.add_edge(\"retrieve_arxiv\", \"synthesize\")\n",
    "builder.add_edge(\"synthesize\", END)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52f9905",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for MultiSourceRAGState\nquestion\n  Input should be a valid string [type=string_type, input_value=('What are transformer ag...n recent research?\"\\n',), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mWhat are transformer agents and how are they evolving in recent research?\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m state = \u001b[43mMultiSourceRAGState\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m result = graph.invoke(state)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Final Answer:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Win 11\\Desktop\\Agentic AI Workspace\\env\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for MultiSourceRAGState\nquestion\n  Input should be a valid string [type=string_type, input_value=('What are transformer ag...n recent research?\"\\n',), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type"
     ]
    }
   ],
   "source": [
    "question = \"What are transformer agents and how are they evolving in recent research?\"\n",
    "state = MultiSourceRAGState(question=question)\n",
    "result = graph.invoke(state)\n",
    "print(\"✅ Final Answer:\")\n",
    "print(result[\"final_answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
