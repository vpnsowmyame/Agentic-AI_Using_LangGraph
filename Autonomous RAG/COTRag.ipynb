{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "347e5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23016a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Vectorstore\n",
    "\n",
    "docs = TextLoader(\"research_notes.txt\",encoding=\"utf-8\").load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(chunks, embedding)\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31ca34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "llm=init_chat_model(\"openai:gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4deefba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  LangGraph State Definition\n",
    "class RAGCoTState(BaseModel):\n",
    "        question: str\n",
    "        sub_steps: List[str] = []\n",
    "        retrieved_docs: List[Document] = []\n",
    "        answer: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea23392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nodes\n",
    "\n",
    "def plan_steps(state:RAGCoTState)->RAGCoTState:\n",
    "        prompt=f\"Break the question into 2-3 reasoning steps:  {state.question}\"\n",
    "        result=llm.invoke(prompt).content\n",
    "        subqs = [line.strip(\"- \") for line in result.splitlines() if line.strip()]\n",
    "        return state.model_copy(update={\"sub_steps\":subqs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15b9c987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve for each step\n",
    "def retrieve_per_step(state:RAGCoTState)-> RAGCoTState:\n",
    "        all_docs=[]\n",
    "        for sub in state.sub_steps:\n",
    "            docs = retriever.invoke(sub)\n",
    "            all_docs.extend(docs)\n",
    "        return state.model_copy(update={\"retrieved_docs\": all_docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f82b13d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Final Answer\n",
    "def generate_answer(state: RAGCoTState) -> RAGCoTState:\n",
    "    context = \"\".join([doc.page_content for doc in state.retrieved_docs])\n",
    "    prompt = f\"\"\"\n",
    "    You are answering a complex question using reasoning and retrieved documents.\n",
    "    Question: {state.question}\n",
    "    Relevant Information:\n",
    "    {context}\n",
    "    Now synthesize a well-reasoned final answer.\n",
    "    \"\"\"\n",
    "    result = llm.invoke(prompt).content.strip()\n",
    "    return state.model_copy(update={\"answer\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e28a6e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph Graph\n",
    "builder = StateGraph(RAGCoTState)\n",
    "builder.add_node(\"planner\", plan_steps)\n",
    "builder.add_node(\"retriever\", retrieve_per_step)\n",
    "builder.add_node(\"responder\", generate_answer)\n",
    "builder.set_entry_point(\"planner\")\n",
    "builder.add_edge(\"planner\", \"retriever\")\n",
    "builder.add_edge(\"retriever\", \"responder\")\n",
    "builder.add_edge(\"responder\", END)\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bf5076d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸªœ Reasoning Steps: ['To determine the additional experiments in Transformer evaluation, one could break down the question into the following reasoning steps:', \"1. **Identify Evaluation Objectives**: Determine what specific aspects of the Transformer model's performance you want to assess. This might include evaluating generalization ability, robustness to noise, handling of long sequences, interpretability, or computational efficiency.\", \"2. **Design Experiments for Each Objective**: For each identified objective, design experiments that can effectively measure the model's performance under those criteria. For example:\", 'To assess generalization, you might conduct experiments on unseen data or different data distributions.', 'To test robustness, you may introduce syntactic or semantic noise into the input data and measure performance degradation.', 'To evaluate handling of long sequences, you could test the model on tasks with varying sequence lengths.', '3. **Compare Across Models and Settings**: Conduct experiments that compare the Transformer model against other architectures or configurations. This can provide insights into the relative benefits and drawbacks of the Transformer in various scenarios relative to other models.', 'These steps guide the development of a comprehensive evaluation strategy for Transformer models, ensuring thorough assessment across diverse performance dimensions.']\n",
      "âœ… Final Answer: The additional experiments in Transformer evaluation as highlighted in the provided document primarily focus on enhancing computational efficiency, improving accuracy and reasoning, and validating performance through human and synthetic evaluations. Summarized, the key additional experiments include:\n",
      "\n",
      "1. **FlashAttention2 Integration**: This is implemented within LLaMA2 to significantly reduce context processing latency by approximately 50%. This entails faster processing of input context, which is crucial for real-time applications.\n",
      "\n",
      "2. **Chain-of-Thought Prompting**: This technique improves accuracy in logic-related tasks by 8% compared to direct answer prompting, and reflective prompting boosts accuracy by an additional 3%. This approach enhances the model's ability to break down complex problems into more manageable parts, thereby improving logical reasoning.\n",
      "\n",
      "3. **Tool-Augmented Prompting**: By integrating tools like LangGraph, Wikipedia, and SQL search, this experiment allows dynamic retrieval and reasoning by retrieval-agent models. This setup enhances the model's capabilities to draw on external information, offering comprehensive answers verified by reliable data sources.\n",
      "\n",
      "4. **Human Evaluation Protocol**: An internal team of annotators assesses the model for fluency, helpfulness, and correctness. Additionally, GPT-4 serves as a synthetic evaluator, offering a benchmark to ensure consistency and quality in model responses.\n",
      "\n",
      "5. **Retrieval Experiments**: Both hybrid dense and sparse retrievers are tested, and Weaviate is compared to FAISS with BM25 reranking. While FAISS is more efficient, Weaviate provides better recall with the help of GraphQL, aiding in more effective data querying and filtering.\n",
      "\n",
      "6. **LoRA Tuning**: Adapter-based fine-tuning with Low-Rank Adaptation (LoRA) is evaluated, showing a 60% reduction in GPU memory usage while being compatible with the PEFT library. This is vital for reducing computational costs and facilitating model adaptability to different tasks or domains.\n",
      "\n",
      "7. **Safety Measures**: Experiments for safety involve using Detoxify for toxicity detection and a zero-shot classifier for out-of-scope concerns, ensuring that the model maintains safety and relevance during interactions.\n",
      "\n",
      "Overall, these experiments focus on making Transformer models more efficient, adaptable, safe, and capable of leveraging external knowledge sources while ensuring high-quality interaction outcomes through rigorous evaluations.\n"
     ]
    }
   ],
   "source": [
    "# Run CoT RAG Agent\\n\",\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"what are the additional eperiments in Transformer evaluation?\"\n",
    "    state = RAGCoTState(question=query)\n",
    "    final = graph.invoke(state)\n",
    "    print(\"ðŸªœ Reasoning Steps:\", final[\"sub_steps\"])\n",
    "    print(\"âœ… Final Answer:\", final[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
